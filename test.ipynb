{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import norm\n",
    "from scipy.stats import lognorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" data_path = \"/home/onyx/Documents/MEMOIRE/memoire/data/sales_train_evaluation.csv\"\n",
    "pkl_path = \"/home/onyx/Documents/MEMOIRE/memoire/data/sales_train_evaluation.pkl\" \"\"\"\n",
    "data_path = \"/home/onyx/Documents/Mémoire/memoire/data/sales_train_evaluation.csv\"\n",
    "pkl_path = \"/home/onyx/Documents/Mémoire/memoire/data/sales_train_evaluation.pkl\"\n",
    "cal_path = \"/home/onyx/Documents/Mémoire/memoire/data/calendar.csv\"\n",
    "\n",
    "alpha = [0.5, 0.6, 0.7, 0.8, 0.9, 0.95, 0.975, 0.99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" forecast_functions = [\n",
    "    FC_avg_3_days,\n",
    "    FC_avg_7_days,\n",
    "    FC_avg_4_same_days\n",
    "]\n",
    "\n",
    "up_to_level_functions = [\n",
    "\n",
    "]\n",
    "\n",
    "safety_stock_functions = [\n",
    "\n",
    "] \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_path: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load data from a CSV or pickle file into a pandas DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "        data_path (str): Path to the data file, can be CSV or pickle.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Loaded DataFrame.\n",
    "    \"\"\"\n",
    "    if data_path.endswith(\".csv\"):\n",
    "        # Load the CSV file\n",
    "        df = pd.read_csv(data_path)\n",
    "        df.to_pickle(pkl_path)\n",
    "    elif data_path.endswith(\".pkl\"):\n",
    "        # Load the pickle file\n",
    "        df = pd.read_pickle(pkl_path)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file format. Please use .csv or .pkl\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scraping_high_zeroes_products(df: pd.DataFrame, n: int) -> pd.DataFrame:\n",
    "    # Count the number of zeroes in each row\n",
    "    df['zero_count'] = (df == 0).sum(axis=1)\n",
    "    \n",
    "    # Sort the DataFrame by the number of zeroes in ascending order\n",
    "    df_sorted = df.sort_values(by='zero_count')\n",
    "    \n",
    "    # Keep only the top 1000 rows with the least number of zeroes\n",
    "    df_top_n = df_sorted.head(n)\n",
    "    \n",
    "    # Drop the 'zero_count' column as it is no longer needed\n",
    "    df_top_n = df_top_n.drop(columns=['zero_count'])\n",
    "    \n",
    "    return df_top_n\n",
    "\n",
    "def preprocess_data(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Preprocess the DataFrame by removing unnecessary columns and converting\n",
    "    the demand columns to numeric types.\n",
    "    \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): Original DataFrame.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Demand matrix with product 'id' as index and days as columns.\n",
    "    \"\"\"\n",
    "    # Remove unnecessary columns\n",
    "    df_demand = df.drop(columns=['item_id', 'dept_id', 'cat_id', 'store_id', 'state_id'])\n",
    "    # Set 'id' as index\n",
    "    demand_matrix = df_demand.set_index('id')\n",
    "\n",
    "    # Load the calendar.csv file\n",
    "    calendar = pd.read_csv(cal_path)\n",
    "\n",
    "    # Get the date columns from the calendar dataframe\n",
    "    date_columns = calendar['date']\n",
    "    demand_matrix.columns = date_columns[0:demand_matrix.shape[1]]\n",
    "    \n",
    "    \n",
    "    return demand_matrix\n",
    "\n",
    "def analyse_data(df: pd.DataFrame) -> [pd.Series, pd.Series]:\n",
    "    means = df.mean(axis=1)\n",
    "    stds = df.std(axis=1)\n",
    "    \n",
    "    return means, stds\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" means, stds = analyse_data(demand_matrix)\n",
    "\n",
    "inv_matrix = norm.ppf(0.95, means.values, stds.values)\n",
    "\n",
    "datadddd = pd.DataFrame(\n",
    "    np.ceil(np.repeat(inv_matrix[:, np.newaxis], demand_matrix.shape[1], axis=1)),\n",
    "    columns=demand_matrix.columns,\n",
    "    index=demand_matrix.index\n",
    ")\n",
    "\n",
    " \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" df= load_data(data_path, pkl_path)\n",
    "df2 = scraping_high_zeroes_products(df)\n",
    "demand_matrix = preprocess_data(df2) \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forecast Computing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Forecast computed on the average of the three lasts day sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FC_avg_n_days(demand_matrix: pd.DataFrame, n: int) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Compute the forecast by averaging the last n days for each product.\n",
    "    \n",
    "    Parameters:\n",
    "        demand_matrix (pd.DataFrame): Demand matrix.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Forecast matrix (rounded up).\n",
    "    \"\"\"\n",
    "    forecast_matrix = demand_matrix.T.rolling(window=n).mean().shift(1).T\n",
    "    return forecast_matrix\n",
    "\n",
    "def FC_med_n_days(demand_matrix: pd.DataFrame, n: int) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Compute the forecast by averaging the last n days for each product.\n",
    "    \n",
    "    Parameters:\n",
    "        demand_matrix (pd.DataFrame): Demand matrix.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Forecast matrix (rounded up).\n",
    "    \"\"\"\n",
    "    forecast_matrix = demand_matrix.T.rolling(window=n).median().shift(1).T\n",
    "    return forecast_matrix\n",
    "\n",
    "def FC_avg_n_same_days(demand_matrix: pd.DataFrame, n: int) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Compute the forecast by averaging the same day of the week over the previous 4 weeks for each product.\n",
    "    \n",
    "    Parameters:\n",
    "        demand_matrix (pd.DataFrame): Demand matrix.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Weekly forecast matrix (rounded up).\n",
    "    \"\"\"\n",
    "    demand_np = demand_matrix.to_numpy()\n",
    "    n_products, n_days = demand_np.shape\n",
    "    weekly_forecast_np = np.full((n_products, n_days), np.nan)\n",
    "    \n",
    "    # For each day of the week (offset from 0 to 6)\n",
    "    for offset in range(7):\n",
    "        idx = np.arange(offset, n_days, 7)\n",
    "        # Need at least 5 weeks to use the previous n weeks\n",
    "        if len(idx) < n+1:\n",
    "            continue\n",
    "        # Create a sliding window view for the previous n weeks\n",
    "        slices = np.stack([demand_np[:, idx[i: i + len(idx) - n]] for i in range(n)], axis=-1)\n",
    "        rolling_mean = np.mean(slices, axis=-1)\n",
    "        target_indices = idx[n:]  # Days to forecast\n",
    "        weekly_forecast_np[:, target_indices] = rolling_mean\n",
    "        \n",
    "    weekly_forecast_matrix = pd.DataFrame(\n",
    "        weekly_forecast_np,\n",
    "        index=demand_matrix.index,\n",
    "        columns=demand_matrix.columns\n",
    "    )\n",
    "    return weekly_forecast_matrix\n",
    "\n",
    "def FC_med_n_same_days(demand_matrix: pd.DataFrame, n: int) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Compute the forecast by taking the median of the same day of the week over the previous 4 weeks for each product.\n",
    "    \n",
    "    Parameters:\n",
    "        demand_matrix (pd.DataFrame): Demand matrix.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Weekly forecast matrix (rounded up).\n",
    "    \"\"\"\n",
    "    demand_np = demand_matrix.to_numpy()\n",
    "    n_products, n_days = demand_np.shape\n",
    "    weekly_forecast_np = np.full((n_products, n_days), np.nan)\n",
    "    \n",
    "    # For each day of the week (offset from 0 to 6)\n",
    "    for offset in range(7):\n",
    "        idx = np.arange(offset, n_days, 7)\n",
    "        # Need at least n+1 weeks to use the previous n weeks\n",
    "        if len(idx) < n+1:\n",
    "            continue\n",
    "        # Create a sliding window view for the previous n weeks\n",
    "        slices = np.stack([demand_np[:, idx[i: i + len(idx) - n]] for i in range(n)], axis=-1)\n",
    "        rolling_med = np.median(slices, axis=-1)\n",
    "        target_indices = idx[n:]  # Days to forecast\n",
    "        weekly_forecast_np[:, target_indices] = rolling_med\n",
    "        \n",
    "    weekly_forecast_matrix = pd.DataFrame(\n",
    "        weekly_forecast_np,\n",
    "        index=demand_matrix.index,\n",
    "        columns=demand_matrix.columns\n",
    "    )\n",
    "    return weekly_forecast_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Safety stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SS_cst(demand_matrix: pd.DataFrame, forecast_matrix: pd.DataFrame, safety_stock_value: int, R: int) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Create a safety stock matrix with a constant integer value for each product and each day.\n",
    "    \n",
    "    Parameters:\n",
    "        demand_matrix (pd.DataFrame): Demand matrix with product index and days as columns.\n",
    "        safety_stock_value (int): The safety stock level to assign.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Safety stock matrix with the same shape as demand_matrix, filled with safety_stock_value.\n",
    "    \"\"\"\n",
    "    safety_stock_matrix = pd.DataFrame(\n",
    "        safety_stock_value,\n",
    "        index=demand_matrix.index,\n",
    "        columns=demand_matrix.columns\n",
    "    )\n",
    "    return safety_stock_matrix\n",
    "\n",
    "def SS_on_forecast(demand_matrix: pd.DataFrame, forecast_matrix: pd.DataFrame, safety_stock_factor: int, R: int) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Create a safety stock matrix constituted of the n+3 day of forecast times the safety_stock_factor.\n",
    "\n",
    "    Parameters:\n",
    "        demand_matrix (pd.DataFrame): Demand matrix with product index and days as columns.\n",
    "        safety_stock_factor: The factor to apply to the forecasted demand.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Safety stock matrix with the same shape as demand_matrix, filled with safety_stock_value.\n",
    "    \"\"\"\n",
    "    safety_stock_matrix = pd.DataFrame(\n",
    "        safety_stock_factor * forecast_matrix.shift(-R, axis=1).values,\n",
    "        index=demand_matrix.index,\n",
    "        columns=demand_matrix.columns\n",
    "    )\n",
    "    return safety_stock_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Up-to-level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" df = load_data(data_path, pkl_path)\n",
    "df = scraping_high_zeroes_products(df)\n",
    "demand_matrix = preprocess_data(df)\n",
    "test_df = demand_matrix.iloc[:5, :15] \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def up_to_level_optimal_restock(demand_matrix, forecast_matrix: pd.DataFrame, safety_stock_matrix: pd.DataFrame, X, min_fill_rate, R):\n",
    "    \"\"\"\n",
    "    Find the optimal fixed restock level that reaches the minimal fill rate.\n",
    "    \n",
    "    Parameters:\n",
    "        min_fill_rate (float): The minimum fill rate to achieve.\n",
    "    \n",
    "    Returns:\n",
    "        int: The optimal fixed restock level.\n",
    "    \"\"\"\n",
    "    demand = demand_matrix.to_numpy()\n",
    "    up_to_level = np.ones(demand_matrix.shape)\n",
    "    _, _, _, _, _, lost_sales = compute_stock(up_to_level, demand)\n",
    "    fill_rates_per_product = compute_fill_rates_per_product(lost_sales, demand)\n",
    "\n",
    "    while not (fill_rates_per_product > min_fill_rate).all():\n",
    "        _, _, _, _, _, lost_sales = compute_stock(up_to_level, demand)\n",
    "        fill_rates_per_product = compute_fill_rates_per_product(lost_sales, demand)\n",
    "        goods = np.where(fill_rates_per_product <= min_fill_rate)\n",
    "        up_to_level[goods] += 1\n",
    "    \n",
    "    for i in range(up_to_level.shape[1]):\n",
    "        if i + R <= up_to_level.shape[1]:\n",
    "            up_to_level[:, i] = np.sum(up_to_level[:, i:i+R], axis=1)\n",
    "        else:\n",
    "            up_to_level[:, i] = np.sum(up_to_level[:, :], axis=1)\n",
    "    \n",
    "    return pd.DataFrame(up_to_level, index=demand_matrix.index, columns=demand_matrix.columns)\n",
    "\n",
    "def compute_fill_rates_per_product(lost_sales, demand):\n",
    "    \"\"\"Compute the fill rate for each product\n",
    "    \n",
    "    Parameters:\n",
    "        lost_sales (ndarray): Numpy array of lost sales.\n",
    "        demand (ndarray): Numpy array of demand.\n",
    "        \n",
    "    Returns:\n",
    "        ndarray: Numpy array of fill rates.\n",
    "    \"\"\"\n",
    "    return 1 - lost_sales.sum(axis=1) / demand.sum(axis=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def up_to_level_on_forecast(demand_matrix, forecast_matrix: pd.DataFrame, safety_stock_matrix: pd.DataFrame, X, min_fill_rate, R):\n",
    "    \"\"\"\n",
    "    Compute the forecast by summing the demand of the next 3 days for each product.\n",
    "    \n",
    "    Parameters:\n",
    "        demand_matrix (pd.DataFrame): Demand matrix.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Forecast matrix (rounded up).\n",
    "    \"\"\"\n",
    "    up_to_level_matrix = forecast_matrix.T.shift(-R+1).rolling(window=R).sum().T\n",
    "    up_to_level_matrix += safety_stock_matrix\n",
    "    \n",
    "    return np.ceil(up_to_level_matrix)\n",
    "\n",
    "def up_to_level_fixed_X(demand_matrix, forecast_matrix: pd.DataFrame, safety_stock_matrix: pd.DataFrame, X, min_fill_rate, R):\n",
    "    ones = np.ones(demand_matrix.shape)\n",
    "    up_to_level = ones * X\n",
    "    up_to_level_matrix = pd.DataFrame(up_to_level, index=demand_matrix.index, columns=demand_matrix.columns)\n",
    "    \n",
    "    up_to_level = up_to_level_matrix.to_numpy()\n",
    "\n",
    "    for i in range(up_to_level.shape[1]):\n",
    "        if i + R <= up_to_level.shape[1]:\n",
    "            up_to_level[:, i] = np.sum(up_to_level[:, i:i+R], axis=1)\n",
    "        else:\n",
    "            up_to_level[:, i] = np.sum(up_to_level[:, :], axis=1)\n",
    "\n",
    "    up_to_level_matrix = pd.DataFrame(up_to_level, index=demand_matrix.index, columns=demand_matrix.columns)\n",
    "\n",
    "    return up_to_level_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def up_to_level_normal_demand(\n",
    "    demand_matrix: pd.DataFrame,\n",
    "    forecast_matrix,       # non utilisé mais conservé pour pipeline\n",
    "    safety_stock_matrix,   # idem\n",
    "    X,                     # idem\n",
    "    min_fill_rate: float,\n",
    "    R: int,\n",
    "    window_size: int = 14  # taille de la fenêtre glissante\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Même principe que before, mais on ne regarde que les `window_size` derniers jours\n",
    "    pour estimer mean et std avant le jour j.\n",
    "    \"\"\"\n",
    "    # 1) Rolling stats (on prend j−window_size à j−1, puis shift pour ne pas prendre j)\n",
    "    roll_means = demand_matrix.rolling(\n",
    "        window=window_size, axis=1, min_periods=1\n",
    "    ).mean().shift(1, axis=1).fillna(0)\n",
    "    roll_stds = demand_matrix.rolling(\n",
    "        window=window_size, axis=1, min_periods=1\n",
    "    ).std(ddof=0).shift(1, axis=1).fillna(0)\n",
    "\n",
    "    # 2) Quantile\n",
    "    quantiles = pd.DataFrame(\n",
    "        norm.ppf(min_fill_rate, loc=roll_means.values, scale=roll_stds.values),\n",
    "        index=demand_matrix.index,\n",
    "        columns=demand_matrix.columns\n",
    "    ).clip(lower=0)\n",
    "\n",
    "    # 3) Somme glissante sur R jours\n",
    "    n_days = demand_matrix.shape[1]\n",
    "    up_to = pd.DataFrame(0, index=demand_matrix.index, columns=demand_matrix.columns)\n",
    "    for j in range(n_days):\n",
    "        end = min(j + R, n_days)\n",
    "        up_to.iloc[:, j] = quantiles.iloc[:, j:end].sum(axis=1)\n",
    "\n",
    "    return np.ceil(up_to)\n",
    "\n",
    "def up_to_level_lognormal_demand(\n",
    "    demand_matrix: pd.DataFrame,\n",
    "    forecast_matrix,       # non utilisé mais conservé pour pipeline\n",
    "    safety_stock_matrix,   # idem\n",
    "    X,                     # idem\n",
    "    min_fill_rate: float,\n",
    "    R: int,\n",
    "    window_size: int = 14  # taille de la fenêtre glissante\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Même principe que before, mais on ne regarde que les `window_size` derniers jours\n",
    "    pour estimer mean et std avant le jour j, avec une distribution log-normale.\n",
    "    \"\"\"\n",
    "    # 1) Rolling stats (on prend j−window_size à j−1, puis shift)\n",
    "    roll_means = demand_matrix.rolling(window=window_size, axis=1, min_periods=1).mean().shift(1, axis=1).fillna(0)\n",
    "    roll_stds = demand_matrix.rolling(window=window_size, axis=1, min_periods=1).std(ddof=0).shift(1, axis=1).fillna(0)\n",
    "    \n",
    "    # 2) Convertir roll_means et roll_stds vers les paramètres de la lognormale\n",
    "    # On suppose que roll_means > 0 pour effectuer le logarithme\n",
    "    sigma = np.sqrt(np.log(1 + (roll_stds / roll_means)**2))\n",
    "    mu = np.log(roll_means) - 0.5 * sigma**2\n",
    "\n",
    "    # 3) Calculer le quantile en utilisant la lognormale : scale = exp(mu), s = sigma \n",
    "    quantile_vals = lognorm.ppf(min_fill_rate, s=sigma, scale=np.exp(mu))\n",
    "    quantiles = pd.DataFrame(quantile_vals, index=demand_matrix.index, columns=demand_matrix.columns).clip(lower=0)\n",
    "    \n",
    "    # 4) Somme glissante sur R jours\n",
    "    n_days = demand_matrix.shape[1]\n",
    "    up_to = pd.DataFrame(0, index=demand_matrix.index, columns=demand_matrix.columns)\n",
    "    for j in range(n_days):\n",
    "        end = min(j + R, n_days)\n",
    "        up_to.iloc[:, j] = quantiles.iloc[:, j:end].sum(axis=1)\n",
    "    \n",
    "    return np.ceil(up_to)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inventory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_stock(up_to_level, demand, order_rate=1):\n",
    "    \"\"\"\n",
    "    Compute various stock management indicators:\n",
    "      - inventory_begin: stock at the beginning of the day\n",
    "      - inventory_end: stock at the end of the day\n",
    "      - T1: stock arriving in 1 day\n",
    "      - T2: stock arriving in 2 days\n",
    "      - sales: actual sales\n",
    "      - lost_sales: unmet demand (lost sales)\n",
    "    \n",
    "    Parameters:\n",
    "        up_to_level (ndarray): Matrix of levels to reach.\n",
    "        demand (ndarray): Demand matrix.\n",
    "        order_rate (int): Interval of days between orders.\n",
    "    \n",
    "    Returns:\n",
    "        tuple of pd.DataFrame: DataFrames for inventory_begin, inventory_end, T1, T2, sales, and lost_sales.\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\" # Conversion vers arrays\n",
    "    demand = demand_matrix.to_numpy()\n",
    "    up_to_level = up_to_level_matrix.to_numpy()\n",
    "    # Ensure no NaN values in the matrices \"\"\"\n",
    "    np.nan_to_num(up_to_level, copy=False)\n",
    "\n",
    "    n_products, n_days = demand.shape\n",
    "\n",
    "    # Initialisation des arrays\n",
    "    inventory_begin = np.zeros_like(demand)\n",
    "    inventory_end = np.zeros_like(demand)\n",
    "    T1 = np.zeros_like(demand)\n",
    "    T2 = np.zeros_like(demand)\n",
    "    sales = np.zeros_like(demand)\n",
    "    lost_sales = np.zeros_like(demand)\n",
    "\n",
    "    # Initialisation jour 0\n",
    "    inventory_begin[:, 0] = 5\n",
    "    T1[:, 0] = 0\n",
    "    T2[:, 0] = up_to_level[:, 0] - inventory_begin[:, 0]\n",
    "    inventory_end[:, 0] = np.maximum(inventory_begin[:, 0] - demand[:, 0], 0)\n",
    "    sales[:, 0] = inventory_begin[:, 0] - inventory_end[:, 0]\n",
    "    lost_sales[:, 0] = np.maximum(demand[:, 0] - sales[:, 0], 0)\n",
    "\n",
    "    # Boucle vectorisée jour par jour\n",
    "    for day in range(1, n_days):\n",
    "        T1[:, day] = T2[:, day - 1]\n",
    "        inventory_begin[:, day] = inventory_end[:, day - 1] + T1[:, day - 1]\n",
    "        inventory_end[:, day] = np.maximum(inventory_begin[:, day] - demand[:, day], 0)\n",
    "\n",
    "        if(day%order_rate == 0):\n",
    "            T2[:, day] = np.nan_to_num(np.maximum(up_to_level[:, day] - inventory_end[:, day] - T1[:, day], 0))\n",
    "        sales[:, day] = inventory_begin[:, day] - inventory_end[:, day]\n",
    "        lost_sales[:, day] = np.maximum(demand[:, day] - sales[:, day], 0)\n",
    "\n",
    "    return inventory_begin, inventory_end, T1, T2, sales, lost_sales\n",
    "\n",
    "#inventory_begin, inventory_end, _, _, _, lost_sales = compute_stock(up_to_level_matrix.to_numpy(), demand_matrix.to_numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_results(demand, lost_sales, inventory_begin, inventory_end, n_days):\n",
    "    \"\"\"\n",
    "    Compute overall stock management metrics:\n",
    "      - Fill rate\n",
    "      - Average inventory\n",
    "      - Ratio of days with perfect service (no lost sales)\n",
    "    \n",
    "    Parameters:\n",
    "        demand_matrix (pd.DataFrame): Demand matrix.\n",
    "        forecast_matrix (pd.DataFrame): Forecast matrix.\n",
    "        up_to_level_matrix (pd.DataFrame): Matrix of levels to reach.\n",
    "    \n",
    "    Returns:\n",
    "        dict: Dictionary containing the results.\n",
    "    \"\"\"\n",
    "\n",
    "    fill_rate = 1 - lost_sales.sum().sum() / demand.sum().sum()\n",
    "    avg_inventory = (inventory_begin.sum().sum() + inventory_end.sum().sum()) / 2 // n_days\n",
    "    # Compute the average percentage of products containing lost sales per day\n",
    "    products_with_lost_sales = (lost_sales > 0).sum(axis=0)/lost_sales.shape[0]\n",
    "    average_percentage_lost_sales = products_with_lost_sales.mean()\n",
    "    \n",
    "    return fill_rate, avg_inventory, average_percentage_lost_sales\n",
    "\n",
    "def compute_pareto(_forecast_func=None, _fc_factor=None,\n",
    "                    _ss_func=SS_cst, _ss_factor=0,\n",
    "                    _up_to_level_func=None, _X=None, _min_fill_rate=None,\n",
    "                    _compute_stock_func=None, _order_rate=1):\n",
    "    results = {}\n",
    "\n",
    "    if type(_ss_factor) == list:\n",
    "        for i in _ss_factor:\n",
    "            fill_rate, avg_inventory, average_percentage_lost_sales = pipeline(\n",
    "                forecast_func=_forecast_func, fc_factor=_fc_factor,\n",
    "                ss_func=_ss_func, ss_factor=i,\n",
    "                up_to_level_func=_up_to_level_func, X=_X, min_fill_rate=_min_fill_rate,\n",
    "                compute_stock_func=_compute_stock_func, order_rate=_order_rate\n",
    "            )\n",
    "            results[i] = (fill_rate, avg_inventory, average_percentage_lost_sales)\n",
    "    elif type(_X) == list:\n",
    "        for i in _X:\n",
    "            fill_rate, avg_inventory, average_percentage_lost_sales = pipeline(\n",
    "                forecast_func=_forecast_func, fc_factor=_fc_factor,\n",
    "                ss_func=_ss_func, ss_factor=_ss_factor,\n",
    "                up_to_level_func=_up_to_level_func, X=i, min_fill_rate=_min_fill_rate,\n",
    "                compute_stock_func=_compute_stock_func, order_rate=_order_rate\n",
    "            )\n",
    "            results[i] = (fill_rate, avg_inventory, average_percentage_lost_sales)\n",
    "    elif type(_min_fill_rate) == list:\n",
    "        for i in _min_fill_rate:\n",
    "            fill_rate, avg_inventory, average_percentage_lost_sales = pipeline(\n",
    "                forecast_func=_forecast_func, fc_factor=_fc_factor,\n",
    "                ss_func=_ss_func, ss_factor=_ss_factor,\n",
    "                up_to_level_func=_up_to_level_func, X=_X, min_fill_rate=i,\n",
    "                compute_stock_func=_compute_stock_func, order_rate=_order_rate\n",
    "            )\n",
    "            results[i] = (fill_rate, avg_inventory, average_percentage_lost_sales)\n",
    "    elif type(_order_rate) == list:\n",
    "        for i in _order_rate:\n",
    "            fill_rate, avg_inventory, average_percentage_lost_sales = pipeline(\n",
    "                forecast_func=_forecast_func, fc_factor=_fc_factor,\n",
    "                ss_func=_ss_func, ss_factor=_ss_factor,\n",
    "                up_to_level_func=_up_to_level_func, X=_X, min_fill_rate=_min_fill_rate,\n",
    "                compute_stock_func=_compute_stock_func, order_rate=i\n",
    "            )\n",
    "            results[i] = (fill_rate, avg_inventory, average_percentage_lost_sales)\n",
    "    else : \n",
    "        raise ValueError(\"No variable to iterate over\")\n",
    "    \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_fill_rates_per_product(lost_sales, demand):\n",
    "    \"\"\"Compute the fill rate for each product\n",
    "    \n",
    "    Parameters:\n",
    "        lost_sales (ndarray): Numpy array of lost sales.\n",
    "        demand (ndarray): Numpy array of demand.\n",
    "        \n",
    "    Returns:\n",
    "        ndarray: Numpy array of fill rates.\n",
    "    \"\"\"\n",
    "    return 1 - lost_sales.sum(axis=1) / demand.sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_stocks(demand_matrix, forecast_matrix, lost_sales, inventory_begin, inventory_end):\n",
    "    \n",
    "    # Transform in pd.DataFrame\n",
    "    lost_sales_matrix = pd.DataFrame(lost_sales, index=demand_matrix.index, columns=demand_matrix.columns)\n",
    "    inventory_begin_matrix = pd.DataFrame(inventory_begin, index=demand_matrix.index, columns=demand_matrix.columns)\n",
    "    inventory_end_matrix = pd.DataFrame(inventory_end, index=demand_matrix.index, columns=demand_matrix.columns)\n",
    "\n",
    "    # Scrap the first 7 days for the plot  \n",
    "    demand_matrix = demand_matrix.iloc[:, 7:]\n",
    "    forecast_matrix = forecast_matrix.iloc[:, 7:]\n",
    "    lost_sales_matrix = lost_sales_matrix.iloc[:, 7:]\n",
    "    inventory_begin_matrix = inventory_begin_matrix.iloc[:, 7:]\n",
    "    inventory_end_matrix = inventory_end_matrix.iloc[:, 7:]\n",
    "    \n",
    "    # Agrégation\n",
    "    total_demand = demand_matrix.sum(axis=0)\n",
    "    total_forecast = forecast_matrix.sum(axis=0)\n",
    "    total_inventory = (inventory_begin_matrix.sum(axis=0) + inventory_end_matrix.sum(axis=0)) / 2\n",
    "    total_lost_sales = lost_sales_matrix.sum(axis=0)\n",
    "\n",
    "    # Paramètres de style\n",
    "    #plt.style.use('seaborn-whitegrid')\n",
    "    plt.figure(figsize=(15, 6))\n",
    "\n",
    "    # Tracés\n",
    "    plt.plot(total_demand, label='Demand', color='dodgerblue', linewidth=1.5)\n",
    "    plt.plot(total_forecast, label='Forecast', color='orangered', linewidth=1.5)\n",
    "    plt.plot(total_lost_sales, label='Lost Sales', color='limegreen', linewidth=1.2)\n",
    "    plt.plot(total_inventory, label='Average Inventory', color='saddlebrown', linewidth=1.5)\n",
    "\n",
    "    # Améliorations visuelles\n",
    "    plt.title('Daily Aggregated Metrics', fontsize=16, fontweight='bold')\n",
    "    plt.xlabel('Date', fontsize=12)\n",
    "    plt.ylabel('Units', fontsize=12)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tick_params(axis='x', labelsize=8)\n",
    "    plt.grid(True, linestyle='--', alpha=0.6)\n",
    "    plt.legend(loc='upper right', frameon=True, framealpha=0.9)\n",
    "\n",
    "    # Limiter les xticks pour lisibilité\n",
    "    xtick_interval = 60  # afficher 1 tick tous les 60 jours\n",
    "    plt.xticks(ticks=range(0, len(total_demand), xtick_interval),\n",
    "            labels=total_demand.index[::xtick_interval], rotation=45)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def plot_smooth_n_days(demand_matrix, forecast_matrix, lost_sales, inventory_begin, inventory_end, rolling_window):\n",
    "    # Transform in pd.DataFrame\n",
    "    lost_sales_matrix = pd.DataFrame(lost_sales, index=demand_matrix.index, columns=demand_matrix.columns)\n",
    "    inventory_begin_matrix = pd.DataFrame(inventory_begin, index=demand_matrix.index, columns=demand_matrix.columns)\n",
    "    inventory_end_matrix = pd.DataFrame(inventory_end, index=demand_matrix.index, columns=demand_matrix.columns)\n",
    "\n",
    "    # Scrap the first 7 days for the plot  \n",
    "    demand_matrix = demand_matrix.iloc[:, 7:]\n",
    "    forecast_matrix = forecast_matrix.iloc[:, 7:]\n",
    "    lost_sales_matrix = lost_sales_matrix.iloc[:, 7:]\n",
    "    inventory_begin_matrix = inventory_begin_matrix.iloc[:, 7:]\n",
    "    inventory_end_matrix = inventory_end_matrix.iloc[:, 7:]\n",
    "\n",
    "    # Agrégation\n",
    "    total_demand = demand_matrix.sum(axis=0)\n",
    "    total_forecast = forecast_matrix.sum(axis=0)\n",
    "    total_inventory = (inventory_begin_matrix.sum(axis=0) + inventory_end_matrix.sum(axis=0)) / 2\n",
    "    total_lost_sales = lost_sales_matrix.sum(axis=0)\n",
    "\n",
    "    # Moyennes glissantes (n jours)\n",
    "    smoothed_demand = total_demand.rolling(window=rolling_window).mean()\n",
    "    smoothed_forecast = total_forecast.rolling(window=rolling_window).mean()\n",
    "    smoothed_inventory = total_inventory.rolling(window=rolling_window).mean()\n",
    "    smoothed_lost_sales = total_lost_sales.rolling(window=rolling_window).mean()\n",
    "    \n",
    "    \n",
    "    # Paramètres de style\n",
    "    #plt.style.use('seaborn-whitegrid')\n",
    "    plt.figure(figsize=(15, 6))\n",
    "\n",
    "    # Tracés\n",
    "    plt.plot(smoothed_demand, label='Demand (Smoothed)', color='dodgerblue')\n",
    "    plt.plot(smoothed_forecast, label='Forecast (Smoothed)', color='orangered')\n",
    "    plt.plot(smoothed_lost_sales, label='Lost Sales (Smoothed)', color='limegreen')\n",
    "    plt.plot(smoothed_inventory, label='Avg Inventory (Smoothed)', color='saddlebrown')\n",
    "\n",
    "    # Améliorations visuelles\n",
    "    plt.title('Smoothed Metrics ('+str(rolling_window)+'-Day Rolling)', fontsize=16, fontweight='bold')\n",
    "    plt.xlabel('Date', fontsize=12)\n",
    "    plt.ylabel('Units', fontsize=12)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tick_params(axis='x', labelsize=8)\n",
    "    plt.grid(True, linestyle='--', alpha=0.6)\n",
    "    plt.legend(loc='upper right', frameon=True, framealpha=0.9)\n",
    "    \n",
    "    # Limiter les xticks pour lisibilité\n",
    "    xtick_interval = 60  # afficher 1 tick tous les 60 jours\n",
    "    plt.xticks(ticks=range(0, len(total_demand), xtick_interval),\n",
    "            labels=total_demand.index[::xtick_interval], rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_histogram(df):\n",
    "    means, stds = analyse_data(df)\n",
    "\n",
    "    # Écart type global sur les valeurs aplaties\n",
    "    sd = np.std(df.values.flatten())\n",
    "\n",
    "    # Filtrage des valeurs <= 2*écart-type\n",
    "    filtered_data = df[df <= 2 * sd]\n",
    "\n",
    "    # Histogramme\n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.hist(filtered_data.values.flatten(), bins=50)\n",
    "    mean = means.mean()\n",
    "    plt.axvline(x=mean, color='red', linestyle='--')\n",
    "    plt.text(mean, 0, 'mu', color='red', verticalalignment='bottom')\n",
    "    plt.xlabel('Values')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Histogram of Values in the Demand')\n",
    "\n",
    "    # Q-Q plot des log(données)\n",
    "    plt.subplot(1, 2, 2)\n",
    "    flattened = filtered_data.values.flatten()\n",
    "    log_data = np.log(flattened[flattened > 0])  # filtrer les zéros ou négatifs\n",
    "    stats.probplot(log_data, dist=\"norm\", plot=plt)\n",
    "    plt.title(\"Q-Q Plot of log(Values)\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_pareto(policy_results):\n",
    "    # Sort the results by average inventory\n",
    "    sorted_items = sorted(policy_results.items(), key=lambda x: x[1][1])\n",
    "    Variables = [item[0] for item in sorted_items]\n",
    "    fill_rates = [item[1][0] for item in sorted_items]\n",
    "    avg_inventories = [item[1][1] for item in sorted_items]\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(avg_inventories, fill_rates, marker='o', linestyle='-', color='blue', label='Frontier')\n",
    "    \n",
    "    # Annotate the points with variables values\n",
    "    for inv, fr, name in zip(avg_inventories, fill_rates, Variables):\n",
    "        plt.annotate(name, (inv, fr), textcoords=\"offset points\", xytext=(0,5), ha='center')\n",
    "    \n",
    "    plt.xlabel(\"Fill Rate\")\n",
    "    plt.ylabel(\"Average Inventory\")\n",
    "    plt.title(\"Strategy Results (Average Inventory vs. Fill Rate)\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "def plot_results(results):\n",
    "    num_results = len(results)\n",
    "    cmap = plt.get_cmap('tab10')\n",
    "    colors = [cmap(i % 10) for i in range(num_results)]\n",
    "    \n",
    "    plt.figure(figsize=(15, 10))\n",
    "\n",
    "    for idx, (key, value) in enumerate(results.items()):\n",
    "        # Sort the results by average inventory\n",
    "        sorted_items = sorted(value.items(), key=lambda x: x[1][1])\n",
    "        Variables = [item[0] for item in sorted_items]\n",
    "        fill_rates = [item[1][0] for item in sorted_items]\n",
    "        avg_inventories = [item[1][1] for item in sorted_items]\n",
    "        \n",
    "        plt.plot(avg_inventories, fill_rates, marker='o', linestyle='-', color=colors[idx], label=key)\n",
    "        plt.annotate(key, \n",
    "                     xy=(avg_inventories[-1], fill_rates[-1]), \n",
    "                     xytext=(10, 0), \n",
    "                     textcoords='offset points', \n",
    "                     fontsize=9, \n",
    "                     color=colors[idx])\n",
    "        \n",
    "        # Annotate the points with variables values\n",
    "        \"\"\" for inv, fr, name in zip(avg_inventories, fill_rates, Variables):\n",
    "            plt.annotate(name, (inv, fr), textcoords=\"offset points\", xytext=(0,5), ha='center') \"\"\"\n",
    "\n",
    "    plt.xlabel(\"Average Inventory\")\n",
    "    plt.ylabel(\"Fill Rate\")\n",
    "    plt.title(\"Results: Average Inventory vs Fill Rate\")\n",
    "    plt.legend(title=\"Policies\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output(function_name: str, fill_rate: float, avg_inventory: float, ratio: float, output_csv: str):\n",
    "    \"\"\"\n",
    "    Update or create a line in the output CSV file for the given function name with the provided metrics.\n",
    "    \n",
    "    Parameters:\n",
    "        function_name (str): Name of the function.\n",
    "        fill_rate (float): Fill rate value.\n",
    "        avg_inventory (float): Average inventory value.\n",
    "        ratio (float): Ratio of days with perfect service.\n",
    "        output_csv (str): Path to the output CSV file.\n",
    "    \"\"\"\n",
    "    # Load the existing CSV file or create a new DataFrame if it doesn't exist\n",
    "    try:\n",
    "        df_output = pd.read_csv(output_csv, index_col='Function Name')\n",
    "    except FileNotFoundError:\n",
    "        df_output = pd.DataFrame(columns=['Function Name', 'Fill Rate', 'Avg Inventory', 'Ratio'])\n",
    "        df_output.set_index('Function Name', inplace=True)\n",
    "    \n",
    "    # Update or create the row for the given function name\n",
    "    df_output.loc[function_name] = [fill_rate, avg_inventory, ratio]\n",
    "    \n",
    "    # Save the updated DataFrame back to the CSV file\n",
    "    df_output.to_csv(output_csv)\n",
    "\n",
    "# Example usage\n",
    "output('FC_avg_2_days', 0.95, 1500, 0.85, 'output_metrics.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  ### DEBUG CELL\n",
    "df = load_data(pkl_path)\n",
    "df = scraping_high_zeroes_products(df, 1000)\n",
    "demand_matrix = preprocess_data(df)\n",
    "#demand_matrix = demand_matrix.iloc[:1, :]# A RETIRER\n",
    "_, n_days = demand_matrix.shape\n",
    "forecast_matrix = FC_avg_n_days(demand_matrix, 3)\n",
    "safety_stock_matrix = SS_on_forecast(demand_matrix, forecast_matrix, 1, R=7)\n",
    "up_to_level_matrix = up_to_level_normal_demand(demand_matrix, forecast_matrix, safety_stock_matrix, X=None, min_fill_rate=0.95, R=7)\n",
    "inventory_begin, inventory_end, T1, T2, sales, lost_sales = compute_stock(up_to_level_matrix.to_numpy(), demand_matrix.to_numpy(),7)\n",
    "fill_rate, avg_inventory, average_percentage_lost_sales = compute_results(demand_matrix, lost_sales, inventory_begin, inventory_end, n_days)\n",
    "print(\"Fill Rate: \", fill_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc1= FC_avg_n_days(demand_matrix, 3)\n",
    "fc2= FC_avg_n_days(demand_matrix, 7)\n",
    "fc3= FC_avg_n_days(demand_matrix, 30)\n",
    "fc4 = FC_avg_4_same_days(demand_matrix)\n",
    "\n",
    "plt.figure(figsize=(15, 8))\n",
    "# Tracés\n",
    "plt.plot(demand_matrix.iloc[:,30:130].sum(axis=0), label='Demand', color='dodgerblue', linewidth=2)\n",
    "plt.plot(fc1.iloc[:,30:130].sum(axis=0), label='Forecast 3 days', color='orangered', linewidth=1)\n",
    "plt.plot(fc2.iloc[:,30:130].sum(axis=0), label='Forecast 7 days', color='limegreen', linewidth=1)\n",
    "plt.plot(fc3.iloc[:,30:130].sum(axis=0), label='Forecast 30 days', color='saddlebrown', linewidth=1)\n",
    "plt.title(\"Aggregated Demand and Forecasts Over Time\")\n",
    "plt.xlabel('Date', fontsize=12)\n",
    "plt.ylabel('Units', fontsize=12)\n",
    "\n",
    "plt.tick_params(axis='x', labelsize=8)\n",
    "plt.grid(True, linestyle='--', alpha=0.6)\n",
    "plt.legend(loc='upper right', frameon=True, framealpha=0.9)\n",
    "\n",
    "# Limiter les xticks pour lisibilité\n",
    "xtick_interval = 7  # afficher 1 tick tous les 60 jours\n",
    "plt.xticks(ticks=range(0, 100, xtick_interval),\n",
    "        labels=demand_matrix.sum(axis=0).index[::xtick_interval], rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_stocks(demand_matrix.iloc[:,30:130], fc1.iloc[:,30:130], lost_sales[:,30:130], inventory_begin[:,30:130], inventory_end[:,30:130])\n",
    "plot_stocks(demand_matrix.iloc[:,30:130], fc2.iloc[:,30:130], lost_sales[:,30:130], inventory_begin[:,30:130], inventory_end[:,30:130])\n",
    "plot_stocks(demand_matrix.iloc[:,30:130], fc3.iloc[:,30:130], lost_sales[:,30:130], inventory_begin[:,30:130], inventory_end[:,30:130])\n",
    "plot_stocks(demand_matrix.iloc[:,30:130], fc4.iloc[:,30:130], lost_sales[:,30:130], inventory_begin[:,30:130], inventory_end[:,30:130])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_stocks(demand_matrix.iloc[:,1:100], fc2.iloc[:,1:100], lost_sales[:,1:100], inventory_begin[:,1:100], inventory_end[:,1:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_stocks(demand_matrix, forecast_matrix, lost_sales, inventory_begin, inventory_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(forecast_func=None, fc_factor=None,\n",
    "             ss_func=SS_cst, ss_factor=0,\n",
    "             up_to_level_func=None, X=None, min_fill_rate=None,\n",
    "             compute_stock_func=None, order_rate=1, lead_time=2,\n",
    "             plot= False):\n",
    "    df = load_data(data_path)\n",
    "    df = scraping_high_zeroes_products(df, n=2000)\n",
    "    demand_matrix = preprocess_data(df)\n",
    "    #demand_matrix = demand_matrix.iloc[:1, :]# A RETIRER\n",
    "    _, n_days = demand_matrix.shape\n",
    "    forecast_matrix = forecast_func(demand_matrix, fc_factor)\n",
    "    safety_stock_matrix = ss_func(demand_matrix, forecast_matrix, ss_factor, order_rate+lead_time)\n",
    "    up_to_level_matrix = up_to_level_func(demand_matrix, forecast_matrix, safety_stock_matrix, X, min_fill_rate, order_rate+lead_time)\n",
    "    inventory_begin, inventory_end, _, _, _, lost_sales = compute_stock_func(up_to_level_matrix.to_numpy(), demand_matrix.to_numpy(), order_rate)\n",
    "    fill_rate, avg_inventory, perfect_service_days_ratio = compute_results(demand_matrix, lost_sales, inventory_begin, inventory_end, n_days)\n",
    "\n",
    "    if plot:\n",
    "        plot_stocks(demand_matrix, forecast_matrix, lost_sales, inventory_begin, inventory_end)\n",
    "        plot_smooth_n_days(demand_matrix, forecast_matrix, lost_sales, inventory_begin, inventory_end, 7)\n",
    "        plot_smooth_n_days(demand_matrix, forecast_matrix, lost_sales, inventory_begin, inventory_end, 30)\n",
    "\n",
    "    print(f\"Fill rate: {fill_rate * 100:.2f}%\")\n",
    "    print(f\"Average inventory: {avg_inventory}\")\n",
    "    print(f\"Average proportion of products not in stock: {perfect_service_days_ratio * 100:.2f}%\")\n",
    "\n",
    "    return fill_rate, avg_inventory, perfect_service_days_ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (R,S) static: Up to level= Fixed S, Safety stock = 0, Variable S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (R,S) static: Up to level= Fixed S, Safety stock = 0, Variable S\n",
    "pipeline(forecast_func=FC_avg_n_days, fc_factor= 3,                                     #forecast\n",
    "         up_to_level_func=up_to_level_fixed_X, X=50, R=7,                       #up to level\n",
    "         compute_stock_func=compute_stock, order_rate=7, plot=True)                    #compute stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xs = [20, 25, 30, 35, 40, 45, 47, 50, 52, 55]\n",
    "policy_results = compute_pareto(\n",
    "    _forecast_func=FC_avg_n_days, _fc_factor=3,\n",
    "    _up_to_level_func=up_to_level_fixed_X, _X=Xs,\n",
    "    _compute_stock_func=compute_stock, _order_rate=7\n",
    ")\n",
    "results['static'] = policy_results\n",
    "#plot_pareto(policy_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (R,S) hybrid: Up to level= 3 days forecast, Safety stock= Fixed s, Variable s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (R,S) hybrid: Up to level= 3 days forecast, Safety stock= Fixed s, Variable s\n",
    "pipeline(forecast_func=FC_avg_n_days, fc_factor=3,                                       #forecast\n",
    "         ss_func=SS_cst, ss_factor=5,                                       #safety stock\n",
    "         up_to_level_func=up_to_level_on_forecast, R=7,                          #up to level\n",
    "         compute_stock_func=compute_stock, order_rate=7)                    #compute stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = [0, 1, 2, 3, 4, 5, 7, 10]\n",
    "policy_results = compute_pareto(\n",
    "    _forecast_func=FC_avg_3_days,\n",
    "    _ss_func=SS_cst, _ss_factor=s,\n",
    "    _up_to_level_func=up_to_level_3_next_days,\n",
    "    _compute_stock_func=compute_stock, _order_rate=7\n",
    ")\n",
    "results['hybrid'] = policy_results\n",
    "#plot_pareto(policy_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (R,S) dynamic: Up to level= 3 days forecast, Safety stock= X*4th day of fc, Variable X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (R,S) dynamic: Up to level= 3 days forecast, Safety stock= X*4th day of fc, Variable X\n",
    "pipeline(forecast_func=FC_avg_n_days, fc_factor= 3,                                     #forecast\n",
    "         ss_func=SS_on_forecast, ss_factor=0.75,                             #safety stock\n",
    "         up_to_level_func=up_to_level_on_forecast,                          #up to level\n",
    "         compute_stock_func=compute_stock, order_rate=7, plot=True)                    #compute stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss_factors = [0, 0.2, 0.4, 0.5, 0.75, 1, 1.25, 1.5, 2, 3]\n",
    "policy_results = compute_pareto(\n",
    "    _forecast_func=FC_avg_n_days, _fc_factor=3,\n",
    "    _ss_func = SS_on_forecast, _ss_factor=ss_factors,\n",
    "    _up_to_level_func=up_to_level_on_forecast,\n",
    "    _compute_stock_func=compute_stock, _order_rate=7\n",
    ")\n",
    "#results['dynamic'] = policy_results\n",
    "plot_pareto(policy_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Theoretical CSL: Up to level= Normal demand, Safety stock= x*sigma, Variable CSL (x=1.64 for 95% CSL)\n",
    "\n",
    "#TODO : adapt to the log-normal data repartition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Theoretical CSL: Up to level= Normal demand, Safety stock= x*sigma, Variable CSL (x=1.64 for 95% CSL)\n",
    "pipeline(forecast_func=FC_avg_n_days, fc_factor=3,                                       #forecast\n",
    "         up_to_level_func=up_to_level_normal_demand, min_fill_rate=0.50,    #up to level\n",
    "         compute_stock_func=compute_stock, order_rate=7, plot=True)                     #compute stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Theoretical CSL: Up to level= Normal demand, Safety stock= x*sigma, Variable CSL (x=1.64 for 95% CSL)\n",
    "pipeline(forecast_func=FC_avg_n_days, fc_factor=3,                                       #forecast\n",
    "         up_to_level_func=up_to_level_lognormal_demand, min_fill_rate=0.50,    #up to level\n",
    "         compute_stock_func=compute_stock, order_rate=7, plot=True)                     #compute stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fill_rates = [0.5, 0.6, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95, 0.98, 0.99]\n",
    "policy_results = compute_pareto(\n",
    "    _forecast_func=FC_avg_n_days, _fc_factor=3,\n",
    "    _up_to_level_func=up_to_level_normal_demand, _min_fill_rate=fill_rates,\n",
    "    _compute_stock_func=compute_stock, _order_rate=7\n",
    ")\n",
    "results['theoretical'] = policy_results\n",
    "plot_pareto(policy_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_results = compute_pareto(\n",
    "    _forecast_func=FC_avg_n_days, _fc_factor=3,\n",
    "    _up_to_level_func=up_to_level_lognormal_demand, _min_fill_rate=fill_rates,\n",
    "    _compute_stock_func=compute_stock, _order_rate=7\n",
    ")\n",
    "results['theoretical'] = policy_results\n",
    "plot_pareto(policy_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss_factors = [0, 0.2, 0.4, 0.5, 0.75, 1, 1.25, 1.5, 2, 3]\n",
    "CSLs = [0.5, 0.6, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95, 0.98, 0.99]\n",
    "n_rolling = [3, 7, 14]\n",
    "n_same = [4, 8]\n",
    "\n",
    "results['theoretical'] = compute_pareto(\n",
    "        _forecast_func=FC_avg_n_days, _fc_factor=3,\n",
    "        _up_to_level_func=up_to_level_normal_demand, _min_fill_rate=CSLs,\n",
    "        _compute_stock_func=compute_stock, _order_rate=7\n",
    "    )\n",
    "for n in n_rolling:\n",
    "    results['moving_avg_'+ str(n) +'_hybrid'] = compute_pareto(\n",
    "        _forecast_func=FC_avg_n_days, _fc_factor=n,\n",
    "        _ss_func = SS_on_forecast, _ss_factor=ss_factors,\n",
    "        _up_to_level_func=up_to_level_on_forecast,\n",
    "        _compute_stock_func=compute_stock, _order_rate=7\n",
    "    )\n",
    "for n in n_same:\n",
    "    results['same_days_avg_'+ str(n) +'_hybrid'] = compute_pareto(\n",
    "        _forecast_func=FC_avg_n_same_days, _fc_factor=n,\n",
    "        _ss_func = SS_on_forecast, _ss_factor=ss_factors,\n",
    "        _up_to_level_func=up_to_level_on_forecast,\n",
    "        _compute_stock_func=compute_stock, _order_rate=7\n",
    "    )\n",
    "    results['same_days_med_'+ str(n) +'_hybrid'] = compute_pareto(\n",
    "        _forecast_func=FC_med_n_same_days, _fc_factor=n,\n",
    "        _ss_func = SS_on_forecast, _ss_factor=ss_factors,\n",
    "        _up_to_level_func=up_to_level_on_forecast,\n",
    "        _compute_stock_func=compute_stock, _order_rate=7\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results['moving_avg_30_hybrid'] = compute_pareto(\n",
    "        _forecast_func=FC_avg_n_days, _fc_factor=30,\n",
    "        _ss_func = SS_on_forecast, _ss_factor=ss_factors,\n",
    "        _up_to_level_func=up_to_level_on_forecast,\n",
    "        _compute_stock_func=compute_stock, _order_rate=7\n",
    "    )\n",
    "results['moving_med_14_hybrid'] = compute_pareto(\n",
    "        _forecast_func=FC_med_n_days, _fc_factor=14,\n",
    "        _ss_func = SS_on_forecast, _ss_factor=ss_factors,\n",
    "        _up_to_level_func=up_to_level_on_forecast,\n",
    "        _compute_stock_func=compute_stock, _order_rate=7\n",
    "    )\n",
    "results['moving_med_30_hybrid'] = compute_pareto(\n",
    "        _forecast_func=FC_med_n_days, _fc_factor=30,\n",
    "        _ss_func = SS_on_forecast, _ss_factor=ss_factors,\n",
    "        _up_to_level_func=up_to_level_on_forecast,\n",
    "        _compute_stock_func=compute_stock, _order_rate=7\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adaptative Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ABC XYZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of elements in results:\", len(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-pourquoi tant de difficulté à monter à 98-99% ?\n",
    "-adaptative variables\n",
    "-ABC XYZ\n",
    "\n",
    "Dans utl modifier 3 jours par R & L"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
